{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545f0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43cf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_urls = {\n",
    "    \"films\": \"https://swapi.dev/api/films/\",\n",
    "    \"people\": \"https://swapi.dev/api/people/\",\n",
    "    \"planets\": \"https://swapi.dev/api/planets/\",\n",
    "    \"species\": \"https://swapi.dev/api/species/\",\n",
    "    \"starships\": \"https://swapi.dev/api/starships/\",\n",
    "    \"vehicles\": \"https://swapi.dev/api/vehicles/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2db40ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films', 'people', 'planets', 'species', 'starships', 'vehicles']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = list(base_urls.keys())\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae41e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\n",
    "    'people' : [\"homeworld\", \"films\", \"species\", \"vehicles\", \"starships\"],\n",
    "    'planets' : ['residents', 'films'],\n",
    "    'films' : [\"characters\", \"planets\", \"starships\", \"vehicles\", \"species\"],\n",
    "    'species' : ['people', 'films'],\n",
    "    'vehicles' : ['pilots', 'films'],\n",
    "    'starships' : ['pilots', 'films']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b3fb84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_items(url, fields):\n",
    "        \n",
    "    # get the content of the url\n",
    "    response = rq.get(url)\n",
    "\n",
    "    # success\n",
    "    if response.status_code == 200:\n",
    "        content = response.json()\n",
    "    elif response.status_code == 404:\n",
    "        print(f'{url} not found!')\n",
    "        return\n",
    "    \n",
    "    items_list = []\n",
    "\n",
    "    next = content['next']\n",
    "    items = content['results']\n",
    "\n",
    "    for item in items:\n",
    "\n",
    "        for field in fields:\n",
    "            id_values = []\n",
    "                           \n",
    "            if item[field]:  # if the field is not empty\n",
    "                # parse the links from starships, vehicles and starships\n",
    "                if field != 'homeworld':  \n",
    "                    for link in item[field]:\n",
    "                        # parse the id value in the link    \n",
    "                        id_values.append(int(link.split('/')[-2]))\n",
    "                    # add the id values into the corresponding field key\n",
    "                    # convert list into tuple, as tuples are hashable\n",
    "                    # each character belongs to only 1 species\n",
    "                    if field != 'species':\n",
    "                        item[field] = tuple(id_values)\n",
    "                    else:\n",
    "                        item[field] = id_values[0]\n",
    "                        \n",
    "                # parse the homeworld (just a single string value)\n",
    "                else:\n",
    "                    # get the homeworld id\n",
    "                    item['homeworld'] = int(item['homeworld'].split('/')[-2])\n",
    "            \n",
    "            # parse species field\n",
    "            # in case of human characters, the species field is an empty list\n",
    "            elif field == 'species' and not item[field]:\n",
    "                item[field] = 1\n",
    "            \n",
    "            # field has no values (empty list)\n",
    "            else:\n",
    "                item[field] = ()\n",
    "                  \n",
    "        # remove created and edited fields\n",
    "        try:\n",
    "            del(item['created'])\n",
    "            del(item['edited'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        items_list.append(item)\n",
    "\n",
    "    return next, items_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7a029",
   "metadata": {},
   "source": [
    "Scrape all the information from the Star Wars API, for all the available categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae62a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films successfully scrapped!\n",
      "people successfully scrapped!\n",
      "planets successfully scrapped!\n",
      "species successfully scrapped!\n",
      "starships successfully scrapped!\n",
      "vehicles successfully scrapped!\n",
      "\n",
      "\n",
      "Whole database fully scrapped!\n",
      "\n",
      "Now the information will be stored in a json file...\n",
      "Scrapped content stored in \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./data/starwars.json'):\n",
    "    items = dict.fromkeys(categories)\n",
    "\n",
    "    for category in categories:\n",
    "        items_list = []\n",
    "        url = base_urls[category]\n",
    "        category_fields = fields[category]\n",
    "        while url:\n",
    "            url, page_items = get_page_items(url, category_fields)\n",
    "            items_list.extend(page_items)\n",
    "        \n",
    "        items[category] = items_list\n",
    "\n",
    "        print(f'{category} successfully scrapped!')\n",
    "\n",
    "    print('\\n\\nWhole database fully scrapped!')\n",
    "    print('\\nNow the information will be stored in a json file...')\n",
    "\n",
    "    # store the information in a json file\n",
    "    filepath = './data/starwars.json'\n",
    "    if not os.path.exists(filepath):\n",
    "        with open(filepath, 'w') as file:\n",
    "            json.dump(items, file, indent=4)\n",
    "\n",
    "        # remove the carriage return character\n",
    "        with open(filepath, 'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        # replace the \\\\r\\\\n (the codes are escaped) string with just \\\\n\n",
    "            for index, line in enumerate(content):\n",
    "                content[index] = line.replace('\\\\r\\\\n', '\\\\n')\n",
    "\n",
    "        # after replacement, store its content\n",
    "        with open(filepath, 'w') as file:\n",
    "            file.writelines(content)\n",
    "        \n",
    "        print(f'Scrapped content stored at: {filepath}')\n",
    "    # The file already exists and will be read\n",
    "    else:\n",
    "        print('starwars.json file already exists!')\n",
    "        print('Information will be read and stored in items dictionary.')\n",
    "        items = {}\n",
    "        with open(filepath, 'r') as file:\n",
    "            items = json.load(file)\n",
    "        print(f'Scrapped content will be stored at {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e4692",
   "metadata": {},
   "source": [
    "## Store the dataframes from each category in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e9413cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_dataframes = dict.fromkeys(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a92b04f",
   "metadata": {},
   "source": [
    "### Generate the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9da1a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in categories:\n",
    "    df = pd.DataFrame(items[cat])\n",
    "    df['id'] = df.index + 1\n",
    "\n",
    "    # rename columns to add '_id' to the \"fields\"\n",
    "    rename_dict = {field : f'{field}_id' for field in fields[cat]}\n",
    "    rename_dict.update({'id' : f'{cat}_id'})\n",
    "    df.rename(columns = rename_dict, inplace = True)\n",
    "\n",
    "    # reorder the columns to place id in first place\n",
    "    all_columns_but_cat_id = [col for col in df.columns if col != f'{cat}_id']\n",
    "    sorted_columns = [f'{cat}_id'] + all_columns_but_cat_id\n",
    "    categories_dataframes[cat] = df[sorted_columns]\n",
    "#df.to_csv('./data/starwars_characters.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e76389",
   "metadata": {},
   "source": [
    "## Junction tables\n",
    "(many-to-many relationships in the database)\n",
    "\n",
    "1. people_films: Links people to the films they appeared in.\n",
    "\n",
    "    - person_id: Foreign Key referencing the people table.\n",
    "    - film_id: Foreign Key referencing the films table.\n",
    "\n",
    "2. people_vehicles: Links people to the vehicles they have piloted.\n",
    "\n",
    "    - person_id: Foreign Key referencing the people table.\n",
    "    - vehicle_id: Foreign Key referencing the vehicles table.\n",
    "\n",
    "3. people_starships: Links people to the starships they have piloted.\n",
    "\n",
    "    - person_id: Foreign Key referencing the people table.\n",
    "    - starship_id: Foreign Key referencing the starships table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0952c256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people_films_junction_table',\n",
       " 'people_vehicles_junction_table',\n",
       " 'people_starships_junction_table']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junction_tables = ['people_films', 'people_vehicles', 'people_starships']\n",
    "junction_tables = [f'{table}_junction_table' for table in junction_tables]\n",
    "junction_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = categories_dataframes['people'].loc[:, ['people_id', 'films_id', 'vehicles_id', 'starships_id']]\n",
    "\n",
    "# junction table for people and films\n",
    "people_film_junction = data.explode('films_id').drop(['vehicles_id', 'starships_id'], axis = 1)\n",
    "\n",
    "# junction table for people and vehicles\n",
    "people_vehicles_junction = data.explode('vehicles_id').drop(['films_id', 'starships_id'], axis = 1)\n",
    "\n",
    "# junction table for people and starships\n",
    "people_starships_junction = data.explode('starships_id').drop(['films_id', 'vehicles_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f23ba8",
   "metadata": {},
   "source": [
    "## Example of joined people and their vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3ebb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.merge(people_vehicles_junction, categories_dataframes['people'], on='people_id', how = 'inner')\n",
    "# df2.rename(columns={'vehicles_id_x' : 'vehicles_id'}, inplace=True)\n",
    "\n",
    "# df2 = pd.merge(df2, categories_dataframes['vehicles'], on='vehicles_id')\n",
    "# #df2.drop(['people_id', 'vehicles_id'], axis = 1)\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be5cae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Category: films\n",
      "\n",
      "columns: ['films_id', 'title', 'episode_id', 'opening_crawl', 'director', 'producer', 'release_date', 'characters_id', 'planets_id', 'starships_id', 'vehicles_id', 'species_id', 'url']\n",
      "\n",
      "\n",
      "Category: people\n",
      "\n",
      "columns: ['people_id', 'name', 'height', 'mass', 'hair_color', 'skin_color', 'eye_color', 'birth_year', 'gender', 'homeworld_id', 'films_id', 'species_id', 'vehicles_id', 'starships_id', 'url']\n",
      "\n",
      "\n",
      "Category: planets\n",
      "\n",
      "columns: ['planets_id', 'name', 'rotation_period', 'orbital_period', 'diameter', 'climate', 'gravity', 'terrain', 'surface_water', 'population', 'residents_id', 'films_id', 'url']\n",
      "\n",
      "\n",
      "Category: species\n",
      "\n",
      "columns: ['species_id', 'name', 'classification', 'designation', 'average_height', 'skin_colors', 'hair_colors', 'eye_colors', 'average_lifespan', 'homeworld', 'language', 'people_id', 'films_id', 'url']\n",
      "\n",
      "\n",
      "Category: starships\n",
      "\n",
      "columns: ['starships_id', 'name', 'model', 'manufacturer', 'cost_in_credits', 'length', 'max_atmosphering_speed', 'crew', 'passengers', 'cargo_capacity', 'consumables', 'hyperdrive_rating', 'MGLT', 'starship_class', 'pilots_id', 'films_id', 'url']\n",
      "\n",
      "\n",
      "Category: vehicles\n",
      "\n",
      "columns: ['vehicles_id', 'name', 'model', 'manufacturer', 'cost_in_credits', 'length', 'max_atmosphering_speed', 'crew', 'passengers', 'cargo_capacity', 'consumables', 'vehicle_class', 'pilots_id', 'films_id', 'url']\n"
     ]
    }
   ],
   "source": [
    "for cat in categories_dataframes.keys():\n",
    "    print(f'\\n\\nCategory: {cat}')\n",
    "    print(f'\\ncolumns: {[ i for i in categories_dataframes[cat].columns]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43222c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
